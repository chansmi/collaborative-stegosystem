wandb:
  project_name: "collaborative-stegosystem"
  entity: "chansmi"

env:
  max_rounds: 1
  stocks: ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'FB']
  reward:
    correct: 1.0
    partial: 0.5
    incorrect: -0.5
  eve_penalty: 2.0

model:
  name: "meta-llama/Llama-2-7b-chat-hf" # "meta-llama/Meta-Llama-3.1-8B-Instruct"
  quantize: true
  save_path: "models/trained_model"
  temperature: 1.2  # Increase this value to make outputs more random
  max_new_tokens: 150
  top_p: 0.9

ppo:
  learning_rate: 1.0e-5
  batch_size: 1
  mini_batch_size: 1
  gradient_accumulation_steps: 1

training:
  num_epochs: 100

data:
  path: "data/stock_data.csv"

openai:
  model: "gpt-4o-mini"
  max_tokens: 100
  temperature: 0.5
  detection_phrase: "insider trading detected"